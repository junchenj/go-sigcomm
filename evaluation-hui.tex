
\tightsection{Implementation and Production Deployment}
\label{sec:eval}

\begin{figure*}[t!]
\centering
\subfigure[Daily improvement (both metrics)]
{
  \includegraphics[width=0.3\textwidth] {figures/eval-perfimp.pdf}
  \label{subfig:buffering-and-bitrate}
}
\subfigure[Buffering ratio (\%): GO vs. per-CDN]
{
	\includegraphics[width=0.3\textwidth]{figures/ab-testing-figures/bufferingratio-new.pdf}
	\label{subfig:eval-case-study:bufferingratio}
}
\subfigure[Avg. bitrate (Kbps): GO vs. per-CDN]
{
	\includegraphics[width=0.3\textwidth]{figures/ab-testing-figures/averagebitrate-new.pdf}
	\label{subfig:eval-case-study:averagebitrate}
}
\tightcaption{Performance Metrics and Improvement from GO}
\label{fig:perf-impr}
\end{figure*}



\tightsubsection{Implementation}
\label{sec:impl}

While there are many details in the building of the GO system, we focus our discussion on two main components: pre-computation and on-line decision making. In order to achieve fast on-line decision making, the GO system has a pre-computation module that (a) computes and updates an AC partition table periodically, and (b) broadcasts the computed table to a set of distributed decision servers that will use the table to make on-line decision making upon requests of clients. 

AC partition table generation is essentially the process of aggregating quality samples into partitions of different ACs and then computing summary statistics for each partition (e.g., mean and standard error of mean).
Our implementation uses Spark~\cite{spark} as the underlying compute framework and is implemented in a single map-reduce stage. 
Quality samples are loaded in parallel from an HDFS source~\cite{hadoop} and distributed amongst the cluster in form of Resilient Distributed Datasets (RDD)~\cite{zaharia2012resilient}. 
%Each node then maps its share of quality samples to a set of preliminary buckets. Common buckets are then shuffled across the cluster and the results are aggregated and collected onto a master machine. 
Currently it takes GO system 12 seconds to process 500K partitions on a 4-node cluster with a total of 64 cores and 512G memory. 
All steps involved in creating the table are horizontally scalable.
We did not spend time to tune the performance of the pre-computation module as it satisfies the requirement of our current deployment where we we re-compute the table between 30 seconds and 1 minute.


The resulting table is broadcasted to a set of of decision makers (DMs) closer to video clients in multiple POPs by way of a distributed messaging system~\cite{kreps2011kafka}. Each entry of the AC partition table is about 100 Bytes uncompressed. For a table of 500K entries, the table is about 50MB.  Assuming an update frequency of one minute, the bandwidth required is 0.83Mbps per POP. Again, we did not tune the performance of this portion of the system as the current implementation satisfies the need for the current deployment scenario. 

Once a decision maker has a table, decision making involves multiple lookups of the table and combines the results from the lookups.  Given that there are $N$ ACs for decision evaluation, and $M$ possible decisions, there are $M \times N$ lookups for a decision to be made. The decision making process is horizontally scalable by adding more decision makers. The average response time from current GO system is $0.62 ^{+}_{-} 0.016$ms, which is insignificant compared to RTT in Internet.

In summary, the current implementation of GO is horizontally scalable and can provide low response times for on-line decision making. 

\tightsubsection{Production Deployment}
\label{subsec:eval_setup}


The GO system is currently deployed in multiple premium publishers. However, there are several practical difficulties of evaluating the performance of GO in production deployment environments.  First, most publishers do not want to perform A/B testing when they understand that the performance of some of the streams may not be optimal when they are grouped by the non-optimized version of the algorithm. Second, with all publishers, there are usually additional business considerations beyond the goal of optimizing the QoS of the video streams. For example, when using multiple CDNs, a publisher would get a lower price from a particular CDN if it would allocate more than a certain percentage of its total traffic to the CDN.  This CDN allocation policy would put additional constraint on the GO optimization algorithm.  Consider a scenario that a publisher has three CDNs $X$, $Y$, and $Z$, and have minimum committed usage percentage on $X$ and $Y$. This would mean that even if CDN $Z$ is the best performing CDN based on the prediction algorithm, beyond certain percentage of traffic, no additional streams would be allocated to it. 

In this section, we are presenting performance results from one publisher who has agreed to allow us to do A/B testing in production with iOS devices (both iPhone and iPad) on their short-form videos (5 minutes).  In this deployment, the publisher utilizes three CDNs with minimum committed percentage usage on each of them and encodes video in 5 bitrate levels (from 700Kbps to 3.5Mbps).The publisher uses the GO system to select the CDN and the nitrate at the start of each session.  The video app is using Appleâ€™s native player for video playback and  HLS protocol as the adaptive 
bitrate switching algorithm to change the bitrate during the video session (without CDN switch). 
 
The results are collected from Jan 1st, 2014 to Jan 25th, 2014 (total of 25 days) with 26.1 million sessions (870K sessions on average per day).
We compare the performances of two algorithms:  baseline, which randomly selects the initial bit rate and CDN at the start of each session,  and GO.




\myparatight{Buffering Ratio and Average Bit Rate}
In Figure~\ref{fig:perf-impr}(a), we show the percentage of improvement of GO over the baseline with two performance metrics: buffering ratio and average bit rate.  In particular, for buffering ratio, we show the percentage of {\em reduction} of buffering ratio for all sessions served by the GO algorithm in each day as compared to all sessions served by the baseline algorithm on the same day; for average bit rate, we show the percentage of {\em increase} of average bitrate over the entire session duration for all sessions served by the GO algorithm in each day as compared to all sessions served by the baseline on the same day.  We present the comparison over a continuous time period of 10 days. There are several points worth noting. First, both metrics are improved simultaneously with GO as compared to the baseline. In contrast, with normal adaptive bitrate protocols without special optimization, the improvement of one metric usually results in the deterioration of the other metric -- for example, the reduction of the buffering ratio usually comes together with the reduction of the average bitrate also.   With GO, both metrics are 
improved simultaneously.  Second, the performance improvement varies daily.  The most likely explanation is that it is due to the CDN performance variation.  To understand this better, we compare the performance of all sessions under GO and the performance of all sessions on each of the three CDNs under the baseline algorithm. This is shown in Figure~\ref{fig:perf-impr}(b) and Figure~\ref{fig:perf-impr}(c) respectively with buffering ratio and average bitrate as performance metrics respectively.  For each Figure, we show the comparison in two separate days.  Some points to note. First, the performances of sessions for different CDNs under the baseline do vary, with respect to both buffering ratio and average bitrate. Second, the sessions under GO performs better than even the sessions for even the best of the three CDNs. This suggests that GO is not only looking for the best CDN on average, but also 
differentiated CDN performance in finer granular partition across time and space.  In addition, if one compares the relative performance among each individual CDNs, the ranking varies between the two days. In particular, with respect to the buffering ratio, CDN3 is the best on Dec 23, but CDN1 is the best on Jan 9; with respect to the average bitrate, CDN3 is the best on both days.  
 
\myparatight{Interaction with the Adaptive Bitrate Protocol}
Since GO in this deployment only selects the bitrate and CDN at the beginning of each session and the HLS protocol controls the bitrate adaptation for the duration of the session, we would like to understand whether how the initial selection decisions by GO impact the future adaptation decisions made by HLS. 
We look at two metrics: the number of bitrate switches per session made by HLS and the ratio between the initial bitrate selected by GO and the dominant bitrate, which is defined to be the bitrate that the sessions plays for the longest duration. A good initial selection would result in less number of bitrate switches in the future and the initial bitrate to dominant bitrate to be close to 1. 
Figure~\ref{fig:bitrate-stability} (a) and (b) show the comparison between Go and the baseline algorithm with respect to both metrics.  As shown in the figure, GO outperforms the baseline algorithm with respect to both metrics. 



\begin{figure}[h!]
\centering
\subfigure[Number of bitrate switches]
{
  \includegraphics[width=0.24\textwidth] {figures/eval-reduceswitch.pdf}
  \label{subfig:reduce-switch}
}
\hspace{-0.6cm}
\subfigure[Initial vs. dominant bitrate]
{
  \includegraphics[width=0.24\textwidth] {figures/eval-initvsdom.pdf}
  \label{subfig:initvsdom}
}
\tightcaption{GO improves bitrate adaptation by selecting a better initial bitrate and thus reducing number of bitrate switches.}
\label{fig:bitrate-stability}
\end{figure}



